{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OMP_NUM_THREADS=2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import pickle\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "get_ipython().magic(u'env OMP_NUM_THREADS=2')\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#get_ipython().magic(u'matplotlib')\n",
    "#get_ipython().magic(u'matplotlib inline')\n",
    "\n",
    "# Set the ransom seed used for the whole program to allow reprocibility\n",
    "np.random.seed(3214412)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '../data/processed'\n",
    "feature_filename = os.path.join(data_dir, 'feature_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Cabin_nan</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Sex     Fare  Pclass_1  Pclass_2  Pclass_3  Embarked_C  \\\n",
       "0         0    1   7.2500         0         0         1           0   \n",
       "1         1    0  71.2833         1         0         0           1   \n",
       "2         1    0   7.9250         0         0         1           0   \n",
       "3         1    0  53.1000         1         0         0           0   \n",
       "4         0    1   8.0500         0         0         1           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Cabin_nan  Cabin_B  Cabin_C  Cabin_D  Cabin_E  \n",
       "0           0           1          1        0        0        0        0  \n",
       "1           0           0          0        0        1        0        0  \n",
       "2           0           1          1        0        0        0        0  \n",
       "3           0           1          0        0        1        0        0  \n",
       "4           0           1          1        0        0        0        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df = pd.read_csv(feature_filename)\n",
    "feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the dependent variable, and remove the Pclass_2 as it's highly correlated with other\n",
    "# varialbles as and not a very useful predictor per feature_analysis\n",
    "ind_df = feature_df.drop(labels=['Survived', 'Pclass_2'], axis=1)\n",
    "dep_df = feature_df.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.759776536313, 0.787709497207, 0.775280898876, 0.769662921348, 0.790960451977\n",
      "Best Score:  0.790960451977\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lrcv = LogisticRegression()\n",
    "cv = cross_val_score(lrcv, ind_df, dep_df, cv=5)\n",
    "print(', '.join(map(str, cv)))\n",
    "print('Best Score: ', max(cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77094972067, 0.720670391061, 0.808988764045, 0.775280898876, 0.774011299435\n",
      "Best Score:  0.808988764045\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "cv = cross_val_score(knn, ind_df, dep_df, cv=5)\n",
    "print(', '.join(map(str, cv)))\n",
    "print('Best Score: ', max(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715083798883, 0.703910614525, 0.808988764045, 0.769662921348, 0.774011299435\n",
      "Best Score:  0.808988764045\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "cv = cross_val_score(knn, ind_df, dep_df, cv=5)\n",
    "print(', '.join(map(str, cv)))\n",
    "print('Best Score: ', max(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.553072625698, 0.754189944134, 0.691011235955, 0.707865168539, 0.734463276836\n",
      "Best Score:  0.754189944134\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=25)\n",
    "cv = cross_val_score(knn, ind_df, dep_df, cv=5)\n",
    "print(', '.join(map(str, cv)))\n",
    "print('Best Score: ', max(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "0.749719416386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(knn, {'n_neighbors':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 25, 50, 100]})\n",
    "gs.fit(ind_df, dep_df)\n",
    "print(gs.best_estimator_.n_neighbors)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "TODO not sure what the value of C should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.614525139665, 0.614525139665, 0.61797752809, 0.61797752809, 0.61581920904\n",
      "Best Score:  0.61797752809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(C=0.025)\n",
    "cv = cross_val_score(svc, ind_df, dep_df, cv=5)\n",
    "print(', '.join(map(str, cv)))\n",
    "print('Best Score: ', max(cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798882681564, 0.793296089385, 0.808988764045, 0.792134831461, 0.813559322034\n",
      "Best Score:  0.813559322034\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=5)\n",
    "cv = cross_val_score(dtc, ind_df, dep_df, cv=5)\n",
    "print(', '.join(map(str, cv)))\n",
    "print('Best Score: ', max(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787709497207, 0.759776536313, 0.870786516854, 0.814606741573, 0.830508474576\n",
      "Best Score:  0.870786516854\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=10)\n",
    "cv = cross_val_score(dtc, ind_df, dep_df, cv=5)\n",
    "print(', '.join(map(str, cv)))\n",
    "print('Best Score: ', max(cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765363128492, 0.776536312849, 0.859550561798, 0.803370786517, 0.841807909605\n",
      "Best Score:  0.859550561798\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=100)\n",
    "cv = cross_val_score(dtc, ind_df, dep_df, cv=5)\n",
    "print(', '.join(map(str, cv)))\n",
    "print('Best Score: ', max(cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765363128492, 0.77094972067, 0.85393258427, 0.808988764045, 0.813559322034\n",
      "Best Score:  0.85393258427\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=1000)\n",
    "cv = cross_val_score(rfc, ind_df, dep_df, cv=5)\n",
    "print(', '.join(map(str, cv)))\n",
    "print('Best Score: ', max(cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.642458100559, 0.715083798883, 0.679775280899, 0.741573033708, 0.779661016949\n",
      "Best Score:  0.779661016949\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "cv = cross_val_score(nb, ind_df, dep_df, cv=5)\n",
    "print(', '.join(map(str, cv)))\n",
    "print('Best Score: ', max(cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Example - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[453,  92],\n",
       "       [ 96, 250]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "lrcvmodel = lrcv.fit(ind_df, dep_df)\n",
    "confusion_matrix(lrcvmodel.predict(ind_df), dep_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the comparison in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "classifiers = OrderedDict([\n",
    "    ('SVC', SVC(C=0.025)),\n",
    "    ('LogisticRegression', LogisticRegression()),\n",
    "    ('KNN3', KNeighborsClassifier(n_neighbors=3)),\n",
    "    ('KNN5', KNeighborsClassifier(n_neighbors=5)),\n",
    "    ('KNN7', KNeighborsClassifier(n_neighbors=7)),\n",
    "    ('KNN10', KNeighborsClassifier(n_neighbors=10)),\n",
    "    ('DecisionTree5', DecisionTreeClassifier(max_depth=5)),\n",
    "    ('DecisionTree10', DecisionTreeClassifier(max_depth=10)),\n",
    "    ('DecisionTree100', DecisionTreeClassifier(max_depth=100)),\n",
    "    ('RandomForest', RandomForestClassifier(n_estimators=1000)),\n",
    "    ('NaiveBayes', GaussianNB())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments\n",
    "* SVC doesn't look like a great model with the F score really low and the CV score not that great\n",
    "   * Maybe with a different C value SVC may be better\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model             Best CV Score\tAverage CV Score\tF Score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/napoleon/.virtualenvs/kaggle_titanic/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/napoleon/.virtualenvs/kaggle_titanic/lib/python3.5/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "m_df = pd.DataFrame(columns=['Name', 'Best_CV_Accuracy', 'Average_CV_Accuracy', 'F_Score', 'Precision', 'Recall'])\n",
    "mname = max(map(len, classifiers.keys()))\n",
    "\n",
    "print(\"Model{0}Best CV Score\\tAverage CV Score\\tF Score\".format(' '*(mname - 5)))\n",
    "mname = max(map(len, classifiers.keys()))\n",
    "for name, model in classifiers.items():\n",
    "    pipeline = make_pipeline(preprocessing.StandardScaler(), model)\n",
    "    cv = cross_val_score(pipeline, ind_df, dep_df, cv=5)\n",
    "    preds = model.fit(ind_df, dep_df).predict(ind_df)\n",
    "    f1 = f1_score(preds, dep_df)\n",
    "    precision = precision_score(preds, dep_df)\n",
    "    recall = recall_score(preds, dep_df)\n",
    "    m_df = m_df.append({\n",
    "            'Name': name, \n",
    "            'Best_CV_Accuracy': max(cv), \n",
    "            'Average_CV_Accuracy': np.mean(cv), \n",
    "            'F_Score': f1,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+-----------------------+-----------+-------------+----------+\n",
      "|    | Name               |   Best_CV_Accuracy |   Average_CV_Accuracy |   F_Score |   Precision |   Recall |\n",
      "|----+--------------------+--------------------+-----------------------+-----------+-------------+----------|\n",
      "|  9 | RandomForest       |           0.853933 |              0.802571 |  0.88685  |    0.847953 | 0.929487 |\n",
      "|  8 | DecisionTree100    |           0.859551 |              0.804819 |  0.885449 |    0.836257 | 0.940789 |\n",
      "|  7 | DecisionTree10     |           0.876404 |              0.816036 |  0.840442 |    0.777778 | 0.914089 |\n",
      "|  2 | KNN3               |           0.803371 |              0.787914 |  0.814056 |    0.812865 | 0.815249 |\n",
      "|  3 | KNN5               |           0.819209 |              0.794687 |  0.78869  |    0.774854 | 0.80303  |\n",
      "|  4 | KNN7               |           0.836158 |              0.801454 |  0.755352 |    0.722222 | 0.791667 |\n",
      "|  6 | DecisionTree5      |           0.813559 |              0.800255 |  0.748344 |    0.660819 | 0.862595 |\n",
      "|  1 | LogisticRegression |           0.79661  |              0.778925 |  0.726744 |    0.730994 | 0.722543 |\n",
      "|  5 | KNN10              |           0.792135 |              0.784524 |  0.689769 |    0.611111 | 0.791667 |\n",
      "| 10 | NaiveBayes         |           0.779661 |              0.71171  |  0.542805 |    0.435673 | 0.719807 |\n",
      "|  0 | SVC                |           0.698324 |              0.668861 |  0        |    0        | 0        |\n",
      "+----+--------------------+--------------------+-----------------------+-----------+-------------+----------+\n"
     ]
    }
   ],
   "source": [
    "m_df = m_df.sort_values(['F_Score', 'Average_CV_Accuracy', 'Best_CV_Accuracy', 'Precision', 'Recall'], \n",
    "                        ascending=False)\n",
    "    \n",
    "from tabulate import tabulate\n",
    "print(tabulate(m_df, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Models\n",
    "* RandomForest\n",
    "* Decision Trees\n",
    "* KNN\n",
    "\n",
    "Not too suprising as these are typical classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Dives "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestclassifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'randomforestclassifier__max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 'randomforestclassifier__max_depth': [10, 100, 1000, None], 'randomforestclassifier__n_estimators': [10, 100, 1000]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = make_pipeline(preprocessing.StandardScaler(), RandomForestClassifier())\n",
    "best_forest = GridSearchCV(forest, \n",
    "                          param_grid=dict(randomforestclassifier__n_estimators=[10, 100, 1000],\n",
    "                                          randomforestclassifier__max_features=list(range(1, 13)),\n",
    "                                          randomforestclassifier__max_depth=[10, 100, 1000, None]),\n",
    "                          n_jobs=-1)\n",
    "best_forest.fit(ind_df, dep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.794612794613\n",
      "F_Score:  0.852255054432\n",
      "Precision:  0.801169590643\n",
      "Recall:  0.910299003322\n",
      "Best Params:\n",
      " ('randomforestclassifier__max_features', 1)\n",
      "('randomforestclassifier__max_depth', 10)\n",
      "('randomforestclassifier__n_estimators', 10)\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: ', best_forest.best_score_)\n",
    "best_forest_preds = best_forest.best_estimator_.fit(ind_df, dep_df).predict(ind_df)\n",
    "print('F_Score: ', f1_score(best_forest_preds, dep_df))\n",
    "print('Precision: ', precision_score(best_forest_preds, dep_df))\n",
    "print('Recall: ', recall_score(best_forest_preds, dep_df))\n",
    "print('Best Params:\\n', '\\n'.join(map(str, best_forest.best_params_.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[522,  68],\n",
       "       [ 27, 274]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(best_forest.predict(ind_df), dep_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('decisiontreeclassifier', DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurit...     min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'decisiontreeclassifier__max_depth': [10, 100, 1000, None], 'decisiontreeclassifier__max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], 'decisiontreeclassifier__max_leaf_nodes': [10, 100, 1000, None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = make_pipeline(preprocessing.StandardScaler(), DecisionTreeClassifier())\n",
    "best_tree = GridSearchCV(tree, \n",
    "                          param_grid=dict(decisiontreeclassifier__max_depth=[10, 100, 1000, None],\n",
    "                                          decisiontreeclassifier__max_features=list(range(1, 13)),\n",
    "                                          decisiontreeclassifier__max_leaf_nodes=[10, 100, 1000, None]),\n",
    "                          n_jobs=-1)\n",
    "best_tree.fit(ind_df, dep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.810325476992\n",
      "F_Score:  0.71652173913\n",
      "Precision:  0.602339181287\n",
      "Recall:  0.884120171674\n",
      "Best Params:\n",
      " ('decisiontreeclassifier__max_depth', 10)\n",
      "('decisiontreeclassifier__max_features', 11)\n",
      "('decisiontreeclassifier__max_leaf_nodes', 10)\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: ', best_tree.best_score_)\n",
    "best_tree_preds = best_tree.best_estimator_.fit(ind_df, dep_df).predict(ind_df)\n",
    "print('F_Score: ', f1_score(best_tree_preds, dep_df))\n",
    "print('Precision: ', precision_score(best_tree_preds, dep_df))\n",
    "print('Recall: ', recall_score(best_tree_preds, dep_df))\n",
    "print('Best Params:\\n', '\\n'.join(map(str, best_tree.best_params_.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[522, 136],\n",
       "       [ 27, 206]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(best_tree.predict(ind_df), dep_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('kneighborsclassifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'kneighborsclassifier__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = make_pipeline(preprocessing.StandardScaler(), KNeighborsClassifier())\n",
    "best_knn = GridSearchCV(knn, \n",
    "                          param_grid=dict(kneighborsclassifier__n_neighbors=list(range(1, 101))),\n",
    "                          n_jobs=-1)\n",
    "best_knn.fit(ind_df, dep_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score:  0.79797979798\n",
      "F_Score:  0.747663551402\n",
      "Precision:  0.701754385965\n",
      "Recall:  0.8\n",
      "Best Params:\n",
      " ('kneighborsclassifier__n_neighbors', 13)\n"
     ]
    }
   ],
   "source": [
    "print('Best Score: ', best_knn.best_score_)\n",
    "best_knn_preds = best_knn.best_estimator_.fit(ind_df, dep_df).predict(ind_df)\n",
    "print('F_Score: ', f1_score(best_knn_preds, dep_df))\n",
    "print('Precision: ', precision_score(best_knn_preds, dep_df))\n",
    "print('Recall: ', recall_score(best_knn_preds, dep_df))\n",
    "print('Best Params:\\n', '\\n'.join(map(str, best_knn.best_params_.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[489, 102],\n",
       "       [ 60, 240]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(best_knn.predict(ind_df), dep_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Gridsearched Random Forest, Decision Tree and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***knn***\n",
      "Best Score:  0.79797979798\n",
      "F_Score:  0.747663551402\n",
      "Precision:  0.701754385965\n",
      "Recall:  0.8\n",
      "***tree***\n",
      "Best Score:  0.810325476992\n",
      "F_Score:  0.718584070796\n",
      "Precision:  0.593567251462\n",
      "Recall:  0.910313901345\n",
      "***forest***\n",
      "Best Score:  0.794612794613\n",
      "F_Score:  0.853582554517\n",
      "Precision:  0.801169590643\n",
      "Recall:  0.913333333333\n"
     ]
    }
   ],
   "source": [
    "for name, gs_model in dict(forest=best_forest, tree=best_tree, knn=best_knn).items():\n",
    "    print('***{}***'.format(name))\n",
    "    print('Best Score: ', gs_model.best_score_)\n",
    "    preds = gs_model.best_estimator_.fit(ind_df, dep_df).predict(ind_df)\n",
    "    print('F_Score: ', f1_score(preds, dep_df))\n",
    "    print('Precision: ', precision_score(preds, dep_df))\n",
    "    print('Recall: ', recall_score(preds, dep_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conculsion\n",
    "Random Forest with optimized paramaters gives the best model\n",
    "1. Not the best Score as the Decision tree gives the best score 0.8035 for forest vs 0.8148 for the tree.  Not a large difference.\n",
    "2. Best F-Score\n",
    "3. Best Precision\n",
    "4. Best Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All predictions match expected:  True\n"
     ]
    }
   ],
   "source": [
    "# Output best model to file\n",
    "# Use file extension 'pkl' as per https://docs.python.org/2/library/pickle.html#example\n",
    "import pickle\n",
    "output_path = os.path.join('../models', 'random_forest_v1.pkl')\n",
    "\n",
    "# Pickle dictionary\n",
    "pickle.dump(best_forest.best_estimator_, open(output_path, 'wb'))\n",
    "\n",
    "# Verify output model\n",
    "loaded_model = pickle.load(open(output_path, 'rb'))\n",
    "preds = loaded_model.predict(ind_df)\n",
    "match = all(loaded_model.predict(ind_df) == best_forest.best_estimator_.predict(ind_df))\n",
    "print('All predictions match expected: ', match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All predictions match expected:  True\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(best_forest.best_estimator_, output_path) \n",
    "\n",
    "# Verify output model\n",
    "loaded_model = joblib.load(output_path)\n",
    "preds = loaded_model.predict(ind_df)\n",
    "match = all(loaded_model.predict(ind_df) == best_forest.best_estimator_.predict(ind_df))\n",
    "print('All predictions match expected: ', match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_titanic",
   "language": "python",
   "name": "kaggle_titanic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
